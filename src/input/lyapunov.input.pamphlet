\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{axiom}
\setlength{\textwidth}{400pt}
\begin{document}
\title{\$SPAD/src/input lyapunov.input}
\author{Maya Ramakrishnan and Timothy Daly}
\maketitle
\begin{abstract}
Maya Ramakrishnan
``A Gentle Introduction to Lyapunov Functions''
ORSUM August 2003\\
\verb|www.or.ms.unimelb.edu.au/handouts/lyaptalk.1.pdf|

Zoran Gaji\'c and Muhammad Tahir Javed Qureshi
``Lyapunov Matrix Equation in System Stability and Control''
ISBN 0-486-46668-X Dover 2008
\end{abstract}
\eject
\tableofcontents
\section{Motivation}
Often systems can be represented or modelled using systems of
differential equations. Given a system, questions which naturally
arise include
\begin{itemize}
\item What are the equilibrium points or orbits
\item Is the system stable?
\item What are the dominant features of the portrait of the orbit?
\end{itemize}

Some common applications of Lyapunov functions are in the area of
\begin{itemize}
\item assessing the importance of non-linear terms in stability and
instability
\item estimating the domain of attraction of an equilibrium point
\item designing control laws that guarantee global asymptotic stability
\end{itemize}

\noindent
Rate control for communications networks {\sl Kelly et al} (1998)
\begin{itemize}
\item Proposed optimization framework
\begin{itemize}
\item Larger system problem decomposed into a User and a Network problem
\end{itemize}
\item Proposed rate control algorithm
\begin{itemize}
\item System of differential equations in the rate/capacity allocated
to each user
\end{itemize}
\item With the correct choice of Lyapunov function, it is shown that:
\begin{itemize}
\item the found equilibrium point is asymptotically stable
\item the lyapunov function closely approximates the Network's 
optimization problem.
\end{itemize}
\end{itemize}

Lyapunov equations have been used to determine the stability of a:
\begin{itemize}
\item F-8 aircraft
\item steam power system
\item voltage regulator
\item synchronous machine connected to an infinite bus
\item distillation column
\item catalytic cracker,
\item gas absorber
\item industrial reactor
\item L-1011 fighter aircraft
\item hydroturbine governors
\item DC motor
\item magnetic tape control system
\item one-dimensional diffusion process
\item aircraft under wind disturbances
\item chemical plant
\end{itemize}

\section{Definitions}

\subsection{The continuous case}
The general differential Lyapunov matrix equation corresponding to
time varying continuous systems is given by 
\begin{equation}
A^T(t)P(t) + P(t)A(t) + Q(t) = \dot{P}(t), \quad P(t_0) = P_0
\end{equation}
where 
$P(t)$ is an $n \times n$ solution matrix of unknown entries,
$A(t)$ is an $n \times n$ system matrix, and
$Q(t)$ is an $n \times n$ symmetric matrix chosen according to
computational convenience and in most cases is positive semi-definite.
If the system is time invariant then $\dot{P} = 0$ (steady state) so
that the above equation becomes the algebraic Lyapunov matrix equation
\[
A^T P + P A + Q = 0
\]
The necessary and sufficient condition for the existence of a
unique solution is that no two eigenvalues of $A$ add up to 0.
\[
\lambda_i + \lambda_j \ne 0, \quad i,j = 1,2,\ldots,n
\]
This condition is satisfied if $A$ is an asymptotically stable matrix
in the continuous-time domain (all eigenvalues of $A$ are located
in the closed left half-plane).

\subsubsection{Continuous, time-invariant linear systems}
Assuming a continous, time-invariant linear system of the form
\[
\dot{x}(t) = Ax(t), \quad x(t_0) = x_0
\]
where $x(t) \in \mathbb{R}^n$ is the system state vector and
$A \in \mathbb{R}^{n \times x}$ is the system matrix.
\noindent
{\bf Definition 2.1.1:}
The linear system is stable if all eigenvalues of the matrix $A$
are in the closed left half of the complex plane and those on the
imaginary axis are distinct roots of the minimal polynomial of $A$.

\noindent
{\bf Definition 2.1.2:}
The linear system is asymptotically stable if all eigenvalues of $A$
are in the open left half of the complex plane.


\subsection{The discrete case}
The corresponding Lyapunov matrix difference equation for discrete-time
varying systems is given by
\[
A^T(k)P(k)A(k) + Q(k) = P(k+1), \quad P(k_0) = P_0
\]
and for time invariant discrete systems at the steady state,
$(P(k+1) = P(k) = P)$, we have the discrete version of the
algebraic Lyapunov matrix equation
\[
A^T P A + Q = P
\]
The condition for the existence of a unique solution is that
no two eigenvalues have a product equal to 1.
\[
\lambda_i\lambda_j \ne 1,\quad i,j = 1,2,\ldots,n
\]
This conditions is satisfied if $A$ is asymptotically stable in the
discrete-time domain (all eigenvalues of $A$ are strictly inside of
the unit circle.

\subsection{Basic Definitions}
Consider the system 
\[ \dot{x} = f(x) \]
where $f$ is not necessarily a linear function of $x$.

\noindent
{\bf Definition 2.3.1:} 
If $\overline{x}$ is an equilibrium point of the system,
then $f(\overline{x}) = 0$.

A system is stable at an equilibrium point if it responds to small changes
from the equilibrium with only small changes in its subsequent states.

\noindent
{\bf Definition 2.3.2:} 
An equilibrium point, $\overline{x}$, is said to be
stable if for all $\epsilon > 0$, there exists a $\delta = \delta(\epsilon)$,
such that
\[
\vert x(t_0) - \overline{x}\vert < \delta \implies
\vert x(t) - \overline{x}\vert < \epsilon, \quad\forall t > t_0
\]

Note that a system can be locally stable.

\noindent
{\bf Definition 2.3.3:} 
We say that $\overline{x}$ is asymptotically stable if it
is stable and
\[ 
\vert x(t) - \overline{x}\vert \rightarrow 0,
 {\rm\ as\ } t \rightarrow \infty
\]

\noindent
{\bf Definition 2.3.4:} 
A system is neutrally stable at $\overline{x}$
if it is stable at $\overline{x}$, but not asymptotically stable.

\noindent
{\bf Definition 2.3.5:} 
A system that is not stable at $\overline{x}$ is
said to be unstable.
\section{Methods of determining stability}
\subsection{Indirect Method}
Consider the system above, where $f$ is not a linear function.
Using Taylor expanson, we have
\[
\dot{x} = Ax + g(x)
\]
where $A$ is the Jacobian matrix of $f(x)$ evaluated at $\overline{x}$, i.e.
\[
A = \left.\frac{\partial f}{\partial x}\right|_{\overline{x}}
\]
and $g(x)$ is a function of the higher order terms.

The resulting linear system is given by
\[
\dot{x} = Ax
\]

The stability of the system can then be assessed using the following rules:
\begin{enumerate}
\item The equilibrium point is asymptotically stable if the linearised
system is strictly stable.
\item The equilibrium point is unstable if the linearised system is
strictly unstable.
\item If the linearised system is marginally stable, then we cannot
conclude anything from the linear approximation.
\end{enumerate}

Consider rule 1. If all the eigenvalues of $A$ have negative real parts,
then the linearised system is asymptotically stable. Problems include
\begin{itemize}
\item If some of the eigenvalues are zero, we cannot conclude anything
about the system.
\item The linear approximation is valid when the initial conditions are
close to $\overline{x}$, however how ``close'' is close?
\end{itemize}
\subsection{Direct Method}
Stability is determined by observing how a scalar function of the state
variables of the system changes in time.

Consider the system 
\[
\dot{x} = f(x)
\]
where
\begin{itemize}
\item $\overline{x}$ is the equilibrium point of the system;
\item $f \in C^1(R)$, where $C^k(R)$ defines the class of all continuous
functions on region $R$ with $k$th derivatives also continuous on $R$; and
\item $x(t^0) = x^0$, $x^0 \in R$
\end{itemize}

\noindent
{\bf Definition 2.3.6:} 
Let $V(x)$ be a real valued scalar function
belonging to $C^0(S)$ for some region $S$ of $R^n$. Suppose
$V(\overline{x}) = 0$. Then,
\begin{enumerate}
\item $V$ is positive definite on $S$ if $V(x) > 0$, for $x \ne \overline{x}$
\item $V$ is negative definite on $S$ if $V(x) < 0$, for $x \ne \overline{x}$
\item If the equalities are not strict, then $V$ is considered positive and
negative semi-definite respectively.
\end{enumerate}

\noindent
{\bf Definition 2.3.7:} 
Let $V(x)$ be a real valued scalar function belonging to
$C^1(R)$. The total derivative along the solution curves of 
$\dot{x} = f(x)$, i.e. with respect to the orbits
$x = x(t,x^0)$ is
\[
\begin{array}{rcl}
\dot{V} & = & \displaystyle\frac{d}{dt}V(x(t,x^0))\\
        & = & \displaystyle\sum_{i=1}^n \frac{\partial V}{\partial{x_i}}
\dot{x_i}(t,x^0)\\
        & = & \displaystyle\nabla V(x)^T f(x)
\end{array}
\]

\noindent
{\bf Theorem 1:} Suppose there exists a function $V(x)$ with the following
properties:
\begin{enumerate}
\item $V(\overline{x}) = 0$
\item $V(x)$ is positive definite for $x \ne \overline{x}$
\item $\dot{V}(x)$ is negative semi-definite along trajectories of 
$\dot{x} = f(x)$
\end{enumerate}
Then $V(x)$ is known as a Lyapunov function and $\overline{x}$ is stable.
Note that if $\dot{V}(x)$ is negative definite, then $\overline{x}$ is
asymptotically stable.

\noindent
{\bf Proof:} This proof will assume that the equilibrium point
$\overline{x} = 0$ for simplicity. It is easily extendable to the
situation where this is not the case.

Let
\begin{itemize}
\item $J_\epsilon$ be the interior of a sphere of radius $\epsilon$, whose
center is at point 0. Further, assume $\epsilon$ is such that 
$J_\epsilon$ lies in the region $R$.
\item $S_\epsilon$ be the spherical surface of the sphere
\end{itemize}
Let $V$ be a function that satisfies properties 1-3 from above.

Since $V(x)$ is continuous and positive on the closed, bounded surface
$S_\epsilon$, by the Minimum Value Theorem for continuous functions,
$V(x)$ has a minimum on $S_\epsilon$. Suppose this minimum is $L$. Then:
\[
0 < L \le V(x),\quad\forall x \in S_\epsilon
\]
Since $V(x)$ is continous and has value 0 at $x=0$, there exists an
open ball $J_delta$ centered at 0, which lies entirely inside
$J_\epsilon$.
\begin{itemize}
\item Choose $\delta$ such that $V(x) < L, \forall x \in J_\delta$
\end{itemize}

Let $x^0$ be a point inside $J_\delta$.
\begin{itemize}
\item Consider the trajectory $x(x^0,t)$ coming from point $x^0$ and
satisfying the system of differential equations under consideration
\item Assume the trajectory travels outside the sphere $S_\epsilon$.
\end{itemize}
Since the trajectory is continuous, it will intersect the boundary
$S_\epsilon$ at some point $x^*$. 
Recall that $V(x)$ satisfies the property
\[
\dot{V} = \sum_{i=0}^n \frac{\partial V}{\partial x_i}\dot{x}_i \le 0
\]
Hence, the function $V$ is not increasing along the trajectory of
$x(x^0,t)$. This means that
\[
V(x^*) \le V(x^0) < L
\]

But $x^* \in S_\epsilon$ and therefore $L \le V(x^*)$. This yields a
contradiction. Hence as $t$ increases, the trajectory $x(x^0,t)$
does not pass outside the limits of $S_\epsilon$.

We have shown, with $\overline{x}=0$, that for all $\epsilon > 0$, 
there exists $\delta(\epsilon) > 0$, such that
\[
\vert x^0 - \overline{x}\vert < \delta \implies
\vert x(x^0,t) - \overline{x} \vert < \epsilon
\]
as required.
\section{Example}
Consider the system
\[
\begin{array}{rcl}
\dot{x}_1 & = & -x_2 + ax_1x_2^2\\
\dot{x}_2 & = & x_1 - bx_1^2x_2
\end{array}
\]
where $a \ne b$.

To find the equilibrium points, set
\[
\begin{array}{rcl}
\dot{x}_1 & = & 0\\
\dot{x}_2 & = & 0
\end{array}
\]

Basic manipulation shows that the equilibrium point is 
$\overline{x}_1 = \overline{x}_2 = 0$

Using the indirect method, consider the linearised system:
\[
\begin{array}{rcl}
\dot{x}_1 & = & Ax\\
\left[
\begin{array}{c}
\dot{x}_1\\
\dot{x}_2
\end{array}
\right] & = &
\left[
\begin{array}{cc}
0 & -1\\
1 & 0
\end{array}
\right] 
\left[
\begin{array}{c}
x_1\\
x_2
\end{array}
\right] 
\end{array}
\]

Next consider the eigenvalues, $\lambda$, of $A$
\[
det\left[
\begin{array}{cc}
-\lambda & -1\\
1 & \lambda
\end{array}
\right] = \lambda^2 + 1 = 0
\]

Recall for asymptotic stability of the linear system, we require
all eigenvalues to have negative real parts. The roots of this 
equation are purely imaginary. Hence we cannot draw any conclusions
about the stability of the non-linear system.

Now using the direct method, consider the function
\[
V(x) = \frac{1}{2}x_1^2 + \frac{1}{2}x_2^2
\]

Clearly, $V(\overline{x}) = 0$. When $x \ne \overline{x}$, $V(x) > 0$, i.e.
it is positive definite.

Next consider $\dot{V}(x)$:
\[
\begin{array}{rcl}
\dot{V}(x) & = & x_1\dot{x}_1 + x_2\dot{x}_2\\
&=& x_1(-x_2 + ax_1x_2^2) + x_2(x_1 - bx_1^2x_2)\\
&=&x_1^2x_2^2(a-b)
\end{array}
\]
For asymptotic stability, we need $\dot{V}(x)$ to be negative definite.
Hence, if $a<b$, then the system is asymptotically stable.

\section{Conclusion}
Lyapunov functions are useful in assessing the stability of systems and
in particular the method can be used
\begin{itemize}
\item for exploring non-linear systems
\item for time varying systems, i.e. $\dot{x} = f(x,t)$
\item to determine both stability and asymptotic stability
\end{itemize}

The drawback is that to find a Lyapunov function is often more of an 
art than a science.
\eject
\begin{chunk}{*}
)set break resume
)sys rm -f lyapunov.output
)spool lyapunov.output
)set message test on
)set message auto off
)clear all
 
)spool 
)lisp (bye)
 
\end{chunk}
\eject
\begin{thebibliography}{99}
\bibitem{1} nothing
\end{thebibliography}
\end{document}
