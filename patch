books/bookvolbib add references

Goal: Proving Axiom Correct

\index{Harper, Robert}
\begin{chunk}{axiom.bib}
@phdthesis{Harp85,
  author = "Harper, Robert",
  title = {{Aspects of the Implementation of Type Theory}},
  school = "Cornell University",
  year = "1985",
  comment = "TR 85-675",
  abstract =
    "This thesis is about building an automated programming logic. For our
    purposes an automated programming logic consists of
    \begin{itemize}
    \item A formal system for reasoning about programs
    \item A proof development environment which includes, at least, an
    editor for the construction of proofs in the logic
    \item Mechanized decision methods to assist in the proof development
    process 
    \item A library mechanism for managing collections of theorems
    \end{itemize}",
  paper = "Harp85.pdf"
}

\end{chunk}

\index{Blanqui, Frederic}
\index{jouannaud, Jean-Pierre}
\index{Okada, Mitsuhiro}
\begin{chunk}{axiom.bib}
@inproceedings{Blan99,
  author = "Blanqui, Frederic and jouannaud, Jean-Pierre and Okada, Mitsuhiro",
  title = {{The Calculus of Algebraic Constructions}},
  booktitle = "Rewriting Techniques and Applications RTA-99",
  year = "1999",
  publisher = "LNCS 1631",
  link = "\url{https://hal.inria.fr/inria-00105545v1/document}",
  abstract = 
    "This paper is concerned with the foundations of the Calculus of
    Algebraic Constructions (CAC), an extension of the Calculus of
    Constructions by inductive data types. CAC generalizes inductive 
    types equipped with higher-order primitive recursion, by providing
    definition s of functions by pattern-matching which capture recursor
    definitions for arbitrary non-dependent and non-polymorphic inductive
    types satisfying a strictly positivity condition. CAC also
    generalizes the first-order framework of abstract data types by
    providing dependent types and higher-order rewrite rules.",
  paper = "Blan99.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Blanqui, Frederic}
\begin{chunk}{axiom.bib}
@article{Blan05,
  author = "Blanqui, Frederic",
  title = {{Inductivev Types in the Calculus of Algebraic Constructions}},
  journal = "Fundamenta Informaticae",
  volume = "65",
  number = "1-2",
  pages = "61-86",
  year = "2005",
  abstract =
    "In a previous work, we proved that an important part of the Calculus
    of Inductive Constructions (CIC), the basis of the Coq proof
    assistant, can be seen as a Calculus of Algebraic Constructions
    (CAC), an extension of the Calculus of Constructions with functions
    and predicates defined by higher-order rewrite rules.  In this
    paper, we prove that almost all CIC can be seen as a CAC, and that it
    can be further extended with non-strictly positive types and
    inductive-recursive types together with non-free constructors and
    pattern-matching on defined symbols.",
  paper = "Blan05.pdf"
}

\end{chunk}

\index{Floyd, Robert W.}
\begin{chunk}{axiom.bib}
@inproceedings{Floy67,
  author = "Floyd, Robert W.",
  title = {{Assigning Meanings to Programs}},
  booktitle = "Proc. Symp. in Applied Mathematics",
  year = "1967",
  pages = "19-32",
  publisher = "American Mathematical Society",
  paper = "Floy67.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Back, R.J.R}
\begin{chunk}{axiom.bib}
@article{Back81,
  author = "Back, R.J.R",
  title = {{On Correct Refinement of Programs}},
  journal = "J. Computer and System Sciences",
  volume = "23",
  number = "1",
  pages = "49-68",
  year = "1981",
  abstract =
    "The stepwise refinement technique is studied from a mathematical
    point of view. A relation of correct refinement between programs is
    defined, based on the principle that refinement steps should be
    correctness preserving. Refinement between programs will therefore
    depend on the criterion of program correctness used. The application
    of the refinement relation in showing the soundness of different
    techniques for refining programs is discussed. Special attention is
    given to the use of abstraction in program construction. Refinement
    with respect to partial and total correctness will be studied in more
    detail, both for deterministic and nondeterministic programs. The
    relationship between these refinement relations and the approximation
    relation of fixpoint semantics will be studied, as well as the
    connection with the predicate transformers used in program
    verification.",
  paper = "Back81.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Morgan, Carroll}
\begin{chunk}{axiom.bib}
@book{Morg98,
  author = "Morgan, Carroll",
  title = {{Programming from Specifcations, 2nd Ed.}},
  publisher = "Prentice Hall",
  year = "1998",
  link = 
"\url{http://www.cse.unsw.edu.au/~carrollm/ProgrammingFromSpecifications.pdf}",
  paper = "Morg98.pdf"
}

\end{chunk}

\index{Filliatre, Jean-Christophe}
\begin{chunk}{axiom.bib}
@phdthesis{Fill99,
  author = "Filliatre, Jean-Christophe",
  title = {{Preuve de programmes imp\'eratifs en th\'eorie des types}},
  school = {{Universit\'e Paris-Sud}},
  year = "1999",
  link = "\url{}",
  paper = "Fill99.pdf"
}

\end{chunk}

\index{Caldwell, James L.}
\begin{chunk}{axiom.bib}
@inproceedings{Cald97,
  author = "Caldwell, James L.",
  title = {{Moving proofs-as-programs into practice}},
  booktitle = "Automated Software Engineering",
  publisher = "IEEE",
  year = "1997",
  abstract =
    "Proofs in the Nuprl system, an implementation of a constructive
    type theory, yield “correct-by-construction” pro- grams.  In this
    paper a new methodology is presented for extracting efficient and
    readable programs from inductive proofs. The resulting extracted
    programs are in a form suitable for use in hierarchical
    verifications in that they are amenable to clean partial evaluation
    via extensions to the Nuprl rewrite system. The method is based on two
    elements: specifications written with careful use of the Nuprl
    set-type to restrict the extracts to strictly computational content;
    and on proofs that use induction tactics that generate extracts
    using familiar fixed-point combinators of the untyped lambda
    calculus. In this paper the methodology is described and its
    application is illustrated by example.",
  paper = "Cald97.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Talpin, Jean-Pierre}
\index{Jouvelot, Pierre}
\begin{chunk}{axiom.bib}
@inproceedings{Talp92,
  author = "Talpin, Jean-Pierre and Jouvelot, Pierre",
  title = {{The Type and Effect Discipline}},
  booktitle = "Conf. on Logic in Computer Science",
  publisher = "Computer Science Press",
  year = "1992",
  abstract =
    "The {\sl type and effect discipline} is a new framework for
    reconstructing the principal type and the minimal effect of
    expressions in implicitly typed polymorphic functional languages that
    support imperative constructs. The type and effect discipline
    outperforms other polymorphic type systems. Just as types abstract
    collections of concrete values, {\sl effects} denote imperative
    operations on regions. {\sl Regions} abstract sets of possibly aliased
    memory locations. 
    
    Effects are used to control type generalization in the presence of
    imperative constructs while regions delimit observable
    side-effects. The observable effects of an expression range over the
    regions that are free in its type environment and its type; effects
    related to local data structures can be discarded during type
    reconstruction. The type of an expression can be generalized with
    respect to the variables that are not free in the type environment or
    in the observable effect.",
  paper = "Talp92.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Davis, Jared Curran}
\begin{chunk}{axiom.bib}
@phdthesis{Davi09,
  author = "Davis, Jared Curran",
  title = {{A Self-Verifying Theorem Prover}},
  school = "University of Texas at Austin",
  year = "2009",
  abstract =
    "Programs have precise semantics, so we can use mathematical proof to
    establish their properties. These proofs are often too large to
    validate with the usual “social process” of mathematics, so instead we
    create and check them with theorem-proving software. This software
    must be advanced enough to make the proof process tractable, but this
    very sophistication casts doubt upon the whole enterprise: who
    verifies the verifier?
    
    We begin with a simple proof checker, Level 1, that only accepts
    proofs composed of the most primitive steps, like Instantiation and
    Cut. This program is so straightforward the ordinary, social process
    can establish its soundness and the consistency of the logical
    theory it implements (so we know theorems are “always true”).
    
    Next, we develop a series of increasingly capable proof checkers,
    Level 2, Level 3, etc.  Each new proof checker accepts new kinds of
    proof steps which were not accepted in the previous levels. By taking
    advantage of these new proof steps, higher-level proofs can be
    written more concisely than lower-level proofs, and can take less time
    to construct and check. Our highest-level proof checker, Level 11, can
    be thought of as a simplified version of the ACL2 or NQTHM theorem
    provers. One contribution of this work is to show how such systems can
    be verified.
    
    To establish that the Level 11 proof checker can be trusted, we first
    use it, without trusting it, to prove the fidelity of every Level n to
    Level 1: whenever Level n accepts a proof of some $\phi$, there exists a
    Level 1 proof of $\phi$. We then mechanically translate the Level 11 proof
    for each Level n into a Level n − 1 proof—that is, we create a Level 1
    proof of Level 2’s fidelity, a Level 2 proof of Level 3’s fidelity,
    and so on. This layering shows that each level can be trusted, and
    allows us to manage the sizes of these proofs.
    
    In this way, our system proves its own fidelity, and trusting Level 11
    only requires us to trust Level 1.",
  paper = "Davi09.pdf"
}

\end{chunk}

\index{Myreen, Magnus O.}
\index{Davis, Jared}
\begin{chunk}{axiom.bib}
@article{Myre14,
  author = "Myreen, Magnus O. and Davis, Jared",
  title = {{The Reflective Milawa Theorem Prover is Sound}},
  journal = "LNAI",
  pages = "421-436",
  year = "2014",
  abstract =
    "Milawa is a theorem prover styled after ACL2 but with a small kernel
    and a powerful reflection mechanism. We have used the HOL4 theorem
    prover to formalize the logic of Milawa, prove the logic sound, and
    prove that the source code for the Milawa kernel (2,000 lines of Lisp)
    is faithful to the logic. Going further, we have combined these
    results with our previous verification of an x86 machine-code
    implementation of a Lisp runtime. Our top-level HOL4 theorem states
    that when Milawa is run on top of our verified Lisp, it will only
    print theorem statements that are semantically true. We believe that
    this top-level theorem is the most comprehensive formal evidence of a
    theorem prover’s soundness to date.".
  paper = "Myre14.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Davis, Jared}
\index{Myreen, Magnus O.}
\begin{chunk}{axiom.bib}
@article{Davi15,
  author = "Davis, Jared and Myreen, Magnus O.",
  title = {{The Reflective Milawa Theorem Prover is Sound}},
  journal = "J. Automated Reasoning",
  volume = "55",
  number = "2",
  pages = "117-183",
  year = "2015",
  abstract =
    "This paper presents, we believe, the most comprehensive evidence of a
    theorem prover’s soundness to date. Our subject is the Milawa theorem
    prover. We present evidence of its soundness down to the machine
    code. Milawa is a theorem prover styled after NQTHM and ACL2. It is
    based on an idealised version of ACL2’s computational logic and
    provides the user with high-level tactics similar to ACL2’s. In
    contrast to NQTHM and ACL2, Milawa has a small kernel that is somewhat
    like an LCF-style system. We explain how the Milawa theorem prover is
    constructed as a sequence of reflective extensions from its
    kernel. The kernel establishes the soundness of these extensions
    during Milawa’s boot-strapping process. Going deeper, we explain how
    we have shown that the Milawa kernel is sound using the HOL4 theorem
    prover. In HOL4, we have formalized its logic, proved the logic sound,
    and proved that the source code for the Milawa kernel (1,700 lines of
    Lisp) faithfully implements this logic. Going even further, we have
    combined these results with the x86 machine-code level verification of
    the Lisp runtime Jitawa. Our top-level theorem states that Milawa can
    never claim to prove anything that is false when it is run on this
    Lisp runtime.",
  paper = "Davi15.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Myreen, Magnus O.}
\begin{chunk}{axiom.bib}
@article{Myre12,
  author = "Myreen, Magnus O.",
  title = {{Functional Programs: Conversions between Deep and Shallow
            Embeddings}},
  journal = "LNCS",
  volume = "7406",
  pages = "412-417",
  year = "2012",
  abstract =
    "This paper presents a method which simplifies verification of deeply
    embedded functional programs. We present a technique by which
    proof-certified equations describing the effect of functional 
    programs (shallow embeddings) can be automatically extracted from their
    operational semantics. Our method can be used in reverse, i.e. from
    shallow to deep embeddings, and thus for implementing certifying code
    synthesis: we have implemented a tool which maps HOL functions to
    equivalent Lisp functions, for which we have a verified Lisp runtime.
    A key benefit, in both directions, is that the verifier does not need
    to understand the operational semantics that gives meanings to the
    deep embeddings.",
  paper = "Myre12.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Myreen, Magnus O.}
\index{Davis, Jared}
\begin{chunk}{axiom.bib}
@article{Myre11,
  author = "Myreen, Magnus O. and Davis, Jared",
  title = {{A Verified Runtime for a Verified Theorem Prover}},
  journal = "NCS",
  volume = "6898",
  pages = "265-280",
  year = "2011",
  abstract =
    "Theorem provers, such as ACL2, HOL, Isabelle and Coq, rely on the
    correctness of runtime systems for programming languages like ML,
    OCaml or Common Lisp. These runtime systems are complex and critical
    to the integrity of the theorem provers.
    
    In this paper, we present a new Lisp runtime which has been formally
    verified and can run the Milawa theorem prover. Our runtime consists
    of 7,500 lines of machine code and is able to complete a 4 gigabyte
    Milawa proof effort. When our runtime is used to carry out Milawa
    proofs, less unverified code must be trusted than with any other
    theorem prover.
    
    Our runtime includes a just-in-time compiler, a copying garbage collector,
    a parser and a printer, all of which are HOL4-verified down to
    the concrete x86 code. We make heavy use of our previously developed
    tools for machine-code verification. This work demonstrates that our
    approach to machine-code verification scales to non-trivial
    applications.",
  paper = "Myre11.pdf",
  keywords = "printed"
}

\end{chunk}
