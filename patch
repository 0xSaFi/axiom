books/bookvolbib add references

Goal: Proving Axiom Sane

\index{Hearn, Peter W.O.}
\begin{chunk}{axiom.bib}
@inproceedings{Hear18,
  author = "O'Hearn, Peter W.",
  title = {{Continuous Reasoning: Scaling the Impact of Formal Methods}},
  booktitle = "LICS 18",
  year = "2018",
  publisher = "ACM",
  isbn = "978-1-4503-5583-4",
  abstract = 
    "This paper describes work in continuous reasoning , where formal
    reasoning about a (changing) codebase is done in a fashion which
    mirrors the iterative, continuous model of software development that
    is increasingly practiced in indus- try. We suggest that advances in
    continuous reasoning will allow formal reasoning to scale to more
    programs, and more programmers. The paper describes the rationale for
    contin- uous reasoning, outlines some success cases from within
    industry, and proposes directions for work by the scientific
    community.",
  paper = "Hear18.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Lester, David R.}
\begin{chunk}{axiom.bib}
@phdthesis{Lest89,
  author = "Lester, David R.",
  title = {{Combinator Graph Reduction: A Congruence and its Applications}},
  year = "1989",
  school = "Oxford University",
  isbn = "0-902928-55-4",
  abstract =
    "The G-Machine is an efficient implementation of lazy functional
    languages developed by Augustsson and Johnsson. This thesis may be
    read as a formal mathematical proof that the G-machine is correct with
    respect to a denotational semantic specification of a simple
    language. It also has more general implications. A simple lazy
    functional language is defined both denotationally and operationally;
    both are defined to handle erroneous results. The operational
    semantics models combinator graph reduction, and is based on reduction
    to weak head normal form. The two semantic definitions are shown to be
    congruent. Because of error handling the language is not
    confluent. Complete strictness is shown to be a necessary and
    sufficient condition for changing lazy function calls to strict
    ones. As strictness analyses are usually used with confluent
    languages, methods are discussed to restore this property. The
    operational semantic model uses indirection nodes to implement
    sharing. An alternative, which is without indirection nodes, is shown
    to be operationally equivalent for terminating programs. The G-machine
    is shown to be a representation of the combinator graph reduction
    operational model. It may be represented by the composition of a small
    set of combinators which correspond to an abstract machine instruction
    set. Using a modified form of graph isomorphism, alternative sequences
    of instructions are shown to be isomorphic, and hence may be used
    interchangeably.",
  paper = "Lest89.pdf"
}

\end{chunk}

\index{Jones, Simon Peyton}
\begin{chunk}{axiom.bib}
@book{Jone00,
  author = "Jones, Simon Peyton",
  title = {{Implementing Functional Languages: A Tutorial}},
  publisher = "University of Glasgow",
  year = "2000",
  link = "\url{https://www.microsoft.com/en-us/research/wp-content/uploads/1992/01/student.pdf}",
  paper = "Jone00.pdf"
}

\end{chunk}

\index{Hudak, Paul}
\begin{chunk}{axiom.bib}
@misc{Huda89,
  author = "Hudak, Paul",
  title = {{The Conception, Evolution, and Application of Functional 
            Programming Languages}},
  link = "\url{http://haskell.cs.yale.edu/wp-content/uploads/2011/01/cs.pdf}",
  year = "1989",
  abstract =
    "The foundations of functional programming languages are examined from
    both historical and technical perspectives.  Their evolution is traced
    through several critical periods: early work on lambda calculus and
    combinatory calculus, Lisp, Iswim, FP, ML, and modern functional
    languages such as Miranda 1 and Haskell.  The fundamental premises on
    which the functional programming methodology stands are critically
    analyzed with respect to philosophical, theoretical, and pragmatic
    concerns. Particular attention is paid to the main features that
    characterize modern functional languages: higher-order functions, lazy
    evaluation, equations and pattern-matching, strong static typing and
    type inference, and data abstraction.  In addition, current research
    areas—such as parallelism, non-determinism, input/output, and
    state-oriented computations—are examined with the goal of predicting
    the future development and application of functional languages.",
  paper = "Huda89.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Grayson, Daniel R.}
\begin{chunk}{axiom.bib}
@misc{Gray18,
  author = "Grayson, Daniel R.",
  title = {{An Introduction to Univalent Foundations for Mathematicians}},
  link = "\url{http://arxiv.org/pdfs/1711.01477v3}",
  year = "2018",
  abstract =
    "We offer an introduction for mathematicians to the univalent
    foundations of Vladimir Voevodsky, aiming to explain how he chose to
    encode mathematics in type theory and how the encoding reveals a
    potentially viable foundation for all of modern mathematics that can
    serve as an alternative to set theory",
  paper = "Gray18.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Breazu-Tannen, Val}
\index{Coquand, Thierry}
\index{Gunter, Carl A.}
\index{Scedrov, Andre}
\begin{chunk}{axiom.bib}
@article{Tann93,
  author = "Breazu-Tannen, Val and Coquand, Thierry and Gunter, Carl A.
           and Scedrov, Andre",
  title = {{Inheritance as Implicit Coercion}},
  journal = "Information and Computation",
  volume = "93",
  pages = "172-221",
  year = "1991",
  abstract =
    "We present a method for providing semantic interpretations for
    languages with a type system featuring inheritance polymorphism. Our
    approach is illustrated on an extension of the language Fun of
    Cardelli and Wegner, which we interpret via a translation into an
    extended polymorphic lambda calculus. Our goal is to interpret
    inheritances in Fun via coercion functions which are definable in the
    target of the translation. Existing techniques in the theory of
    semantic domains can be then used to interpret the extended
    polymorphic lambda calculus, thus providing many models for the
    original language. This technique makes it possible to model a rich
    type discipline which includes parametric polymorphism and recursive
    types as well as inheritance. A central difficulty in providing
    interpretations for explit type disciplines featuring inheritance in
    the sense discussed in this paper arises from the fact that programs
    can type-check in more than one way. Since interpretations follow the
    type-checking derivations, coherence theorems are required: that is,
    one must prove that the meaning of a program does not depend on the
    way it was type-checked. Proofs of such theorems for our proposed
    interpretation are the basic technical results of this paper. 
    Interestingly, proving coherence in the presence of recursive
    types, variants, and abstract types forced us to reexamine fundamental
    equational properties that arise in proof theory (in the form of
    commutative reductions) and domain theory (in the form of strict vs
    non-strict functions).",
  paper = "Tann93.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Kauers, Manuel}
\begin{chunk}{axiom.bib}
@inproceedings{Kaue08b,
  author = "Kauers, Manuel",
  title = {{Computer Algebra for Special Function Inequalities}},
  booktitle = "Tapas in Experimental Mathematics",
  pages = "215-235",
  year = "2008",
  abstract =
    "Recent coputer proofs for some special function inequalities are
    presented. The algorithmic ideas underlying these computer proofs
    are described, and the conceptual difference to existing
    algorithms for proving special function identities is discussed.",
  paper = "Kaue08b.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Callaghan, Paul}
\begin{chunk}{axiom.bib}
@article{Call08,
  author = "Callaghan, Paul",
  title = {{Coercive Subtyping via Mappings of Reduction Behaviour}},
  journal = "Electronic Notes in Theoretical Computer Science",
  volume = "196",
  pages = "53-68",
  year = "2008",
  abstract =
    "This paper reports preliminary work on a novel approach to
    Coercive Subtyping that is based on relationships between
    reduction behaviour of source and target types in coerced
    terms. Coercive subtyping is a subset of record-based subtyping,
    allowing so-called coercion functions to carry the subtyping. This
    allows many novel and powerful forms of subtyping and
    abbreviation, with applicaions including interfaces to theorem
    provers and programming with dependent type systems. However, the
    use of coercion functions introduces non-trivial overheads, and
    requires difficult proof of properties such as coherence in order
    to guarantee sensible results. These points restrict the
    practicality of coercive subtyping. We begin with the idea that
    coercing a value $v$ from type $U$ to a type %T% intuitively means
    that we wish to compute with $v$ as if it was a value in $T$, not
    that $v$ must be converted into a value in $T$. Instead, we
    explore how to compute on $U$ in terms of computation on $T$, and
    develop a framework for mapping computations on some $T$ on
    computations on some $U$ via a simple extension of the elimination
    rule of $T$. By exposing how computations on different types are
    relatd, we gain insight on and make progress with several aspects
    of coercive subtyping, including (a) distinguishing classes of
    coercion and finding reasons to deprecate use of some classes; (b)
    alternative techniques for improving key properties of coercions;
    (c) greater efficiency from implementations of coercions.",
  paper = "Call08.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Harper, Robert}
\begin{chunk}{axiom.bib}
@misc{Harp18,
  author = "Harper, Robert",
  title = {{Computational Type Theory}},
  year = "2018",
  link = 
  "\url{http://www.cs.uoregon.edu/research/summerschool/summer18/topics.php}",
  comment = "OPLSS 2018"
}

\end{chunk}

\index{Aspinall, David}
\index{Compagnoni, Adriana}
\begin{chunk}{axiom.bib}
@article{Aspi01,
  author = "Aspinall, David and Compagnoni, Adriana",
  title = {{Subtyping Dependent Types}},
  journal = "Theoretical Computer Science",
  volume = "266",
  number = "1-2",
  pages = "273-309",
  year = "2001",
  abstract =
    "The need for subtyping in type-systems with dependent
    types has been realized for some years. But it is hard to
    prove that systems combining the two features have 
    fundamental properties such as subject reduction. Here we in-
    vestigate a subtyping extension of the system $\lambda$P
    which is an abstract version of the type system of the 
    Edinburgh Logical Framework LF. By using an equivalent 
    formulation, we establish some important properties of 
    the new system $\lambda{\rm P}_{\le}$ including subject 
    reduction. Our analysis culminates in a complete and 
    terminating algorithm which establishes the decidability 
    of type-checking",
  paper = "Aspi01.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Gordon, Michael J.}
\index{Milner, Arthur J.}
\index{Wadsworth, Christopher P.}
\begin{chunk}{axiom.bib}
@book{Gord79,
  author = "Gordon, Michael J. and Milner, Arthur J. and 
            Wadsworth, Christopher P.",
  title = "Edinburgh LCF",
  publisher = "Springer-Verlag",
  year = "1979",
  isbn = "978-3540097242"
}

\end{chunk}

\index{Gordon, Michael J.}
\index{Milner, Arthur J.}
\index{Wadsworth, Christopher P.}
\begin{chunk}{axiom.bib}
@incollection{Gord79a,
  author = "Gordon, Michael J. and Milner, Arthur J. and 
            Wadsworth, Christopher P.",
  title = "Front Matter",
  booktitle = "Edinburgh LCF",
  publisher = "Springer-Verlag",
  year = "1979",
  isbn = "978-3540097242",
  pages = "1-8",
  paper = "Gord79a.pdf"
}

\end{chunk}

\index{Gordon, Michael J.}
\index{Milner, Arthur J.}
\index{Wadsworth, Christopher P.}
\begin{chunk}{axiom.bib}
@incollection{Gord79b,
  author = "Gordon, Michael J. and Milner, Arthur J. and 
            Wadsworth, Christopher P.",
  title = "Introduction",
  booktitle = "Edinburgh LCF",
  publisher = "Springer-Verlag",
  year = "1979",
  isbn = "978-3540097242",
  pages = "1-12",
  paper = "Gord79b.pdf"
}

\end{chunk}

\index{Gordon, Michael J.}
\index{Milner, Arthur J.}
\index{Wadsworth, Christopher P.}
\begin{chunk}{axiom.bib}
@incollection{Gord79c,
  author = "Gordon, Michael J. and Milner, Arthur J. and 
            Wadsworth, Christopher P.",
  title = "ML",
  booktitle = "Edinburgh LCF",
  publisher = "Springer-Verlag",
  year = "1979",
  isbn = "978-3540097242",
  pages = "13-61",
  paper = "Gord79c.pdf"
}

\end{chunk}

\index{Gordon, Michael J.}
\index{Milner, Arthur J.}
\index{Wadsworth, Christopher P.}
\begin{chunk}{axiom.bib}
@incollection{Gord79d,
  author = "Gordon, Michael J. and Milner, Arthur J. and 
            Wadsworth, Christopher P.",
  title = "PPLAMBDA",
  booktitle = "Edinburgh LCF",
  publisher = "Springer-Verlag",
  year = "1979",
  isbn = "978-3540097242",
  pages = "62-86",
  paper = "Gord79d.pdf"
}

\end{chunk}

\index{Gordon, Michael J.}
\index{Milner, Arthur J.}
\index{Wadsworth, Christopher P.}
\begin{chunk}{axiom.bib}
@incollection{Gord79e,
  author = "Gordon, Michael J. and Milner, Arthur J. and 
            Wadsworth, Christopher P.",
  title = "APPENDIX",
  booktitle = "Edinburgh LCF",
  publisher = "Springer-Verlag",
  year = "1979",
  isbn = "978-3540097242",
  pages = "87-159",
  paper = "Gord79e.pdf"
}

\end{chunk}

\index{Reynolds, John C.}
\begin{chunk}{axiom.bib}
@misc{Reyn94,
  author = "Reynolds, John C.",
  title = {{An Introduction to the Polymorphic Lambda Calculus}},
  year = "1994",
  paper = "Reyn94.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Meili, Mario}
\begin{chunk}{axiom.bib}
@misc{Meilxx,
  author = "Meili, Mario",
  title = {{Polymorphic Lambda Calculus}},
  year = "unknown",
  link = "\urlhttp://wiki.ifs.hsr.ch/SemProgAnTr/files/mmeili_polymorphic_lambda_calculus_final.pdf}",
  paper = "Meilxx.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Wadler, Philip}
\begin{chunk}{axiom.bib}
@misc{Wadl03,
  author = "Wadler, Philip",
  title = {{The Girard-Reynolds Isomorphism}},
  journal = "Information and Computation",
  volume = "186",
  number = "2",
  pages = "260-280",
  year = "2003",
  abstract = 
    "The second-order polymorphic lambda calculus, F2, was
    independently discovered by Girard and Reynolds. Girard
    additionally proved a {\sl representation} theorem: every function
    on natural numbers that can be proved total in second-order
    intutionistic propositional logic, P2, can be represented in
    F2. Reynolds additionally proved an {\sl abstraction} theorem: for
    a suitable notion of logical relation, every term in F2 takes
    related arguments into related results. We observe that the
    essence of Girard's result is a projection from P2 into F2, and
    that the essence of Reynolds's result is an embedding of F2 into
    P2, and that the Reynolds embedding followed by the Girard
    projection is the identity. The Girard projection discards all
    first-order quantifiers, so it seems unreasonable to expect that
    the Girard projection followed by the Reynolds embedding should
    also be the identity. However, we show that in the presence of
    Reynolds's parametricity property that this is indeed the case,
    for propositions corresponding to inductive definitions of
    naturals, products, sums, and fixpoint types.",
  paper = "Wadl03.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Barendregt, Hendrik Pieter}
\begin{chunk}{axiom.bib}
@article{Bare91,
  author = "Barendregt, Hendrik Pieter",
  title = {{An Introduction to Generalized Type Systems}},
  journal = "Journal of Functional Programming",
  volume = "1",
  number = "2",
  year = "1991",
  pages = "125-154",
  abstract =
    "Programming languages often come with type systems. Some of these are
    simple, others are sophisticated. As a stylistic representation of
    types in programming languages several versions of typed lambda
    calculus are studied. During the last 20 years many of these systems
    have appeared, so there is some need of classification. Working
    towards a taxonomy, Barendregt (1991) gives a fine-structure of the
    theory of constructions (Coquand and Huet 1988) in the form of a
    canonical cube of eight type systems ordered by inclusion. Berardi
    (1988) and Terlouw (1988) have independently generalized the method of
    constructing systems in the λ-cube. Moreover, Berardi (1988, 1990)
    showed that the generalized type systems are flexible enough to
    describe many logical systems. In that way the well-known
    propositions-as-types interpretation obtains a nice canonical form.",
  paper = "Bare91.pdf",
  keywords = "printed"
}

\end{chunk}

\index{Arkoudas, Konstantine}
\index{Musser, David}
\begin{chunk}{axiom.bib}
@book{Arko17,
  author = "Arkoudas, Konstantine and Musser, David",
  title = {{Fundamental Proof Methods in Computer Science}},
  publisher = "MIT Press",
  year = "2017",
  isbn = "978-0262035538"
}

\end{chunk}

\index{Dahl, O.-J.}
\index{Dijkstra, E.W.}
\index{Hoare, C.A.R}
\begin{chunk}{axiom.bib}
@book{Dahl72a,
  author = "Dahl, O.-J. and Dijkstra, E.W. and Hoare, C.A.R",
  title = {{Structured Programming}},
  publisher = "Academic Press",
  year = "1972",
  isbn = "0-12-200556-2"
}

\end{chunk}

\index{Nipkow, Tobias}
\index{Tabacznyj, Christophe}
\index{Paulson, Lawrence C.}
\index{Chaieb, Amine}
\index{Rasmussen, Thomas M.}
\index{Avigad, Jeremy}
\begin{chunk}{axiom.bib}
@misc{Nipk18,
  author = "Nipkow, Tobias and Tabacznyj, Christophe and 
            Paulson, Lawrence C. and Chaieb, Amine and Rasmussen, Thomas M.
            and Avigad, Jeremy",
  title = {{GCD in Isabelle}},
  link = "\url{http://isabelle.in.tum.ed/dist/library/HOL/HOL/GCD.html}",
  year = "2018"
}

\end{chunk}

\index{McCarthy, John}
\index{Abrahams, Paul W.}
\index{Edwards, Daniel J.}
\index{Hart, Timothy P.}
\index{Levin, Michael I.}
\begin{chunk}{axiom.bib}
@book{Mcca62,
  author = "McCarthy, John and Abrahams, Paul W. and Edwards, Daniel J.
            and Hart, Timothy P. and Levin, Michael I.",
  title = {{LISP 1.5 Programmer's Manual}},
  link = "\url{http://www.softwarepreservation.org/projects/LISP/book/LISP%201.5%20Programmers%20Manual.pdf}",
  publisher = "MIT Press",
  isbn = "0-262-13011-4",
  year = "1962"
}

\end{chunk}
